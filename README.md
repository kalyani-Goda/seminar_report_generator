# Seminar Report Generator ðŸ“ðŸ¤–

An LLM-powered Seminar Report Generator built using **LangGraph**, **RAG**, and **Streamlit**.  
The system automatically generates structured academic seminar reports from user input and reference documents.

---

## âœ¨ Features

- **Multi-Agent Workflow**: Planning, research, writing, and validation agents
- **Hybrid RAG**: Combine local PDFs with web search
- **Smart State Management**: LangGraph-powered workflow orchestration
- **User-Friendly Interface**: Streamlit web app with PDF upload
- **Export Options**: Download as Markdown or PDF
- **Async Processing**: Fast parallel operations


---

## ðŸ—ï¸ Project Architecture

ðŸ“¦ seminar-report-generator
â”£ ðŸ“‚ config # Configuration
â”£ ðŸ“‚ notebooks # Experiments
â”£ ðŸ“‚ src # Source code
â”ƒ â”£ ðŸ“œ graph_builder.py
â”ƒ â”£ ðŸ“œ nodes.py
â”ƒ â”£ ðŸ“œ models.py
â”ƒ â”£ ðŸ“œ prompts.py
â”ƒ â”— ðŸ“œ rag_setup.py
â”£ ðŸ“‚ streamlit_app # Web interface
â”£ ðŸ“œ requirements.txt
â”£ ðŸ“œ pyproject.toml
â”— ðŸ“œ README.md



---

## âš™ï¸ Tech Stack

- **Python 3.11**
- **LangGraph**
- **LangChain**
- **Vector Database (RAG)**
- **Streamlit**

---

## ðŸ”‘ Environment Setup

Create a `.env` file based on the example:

```bash
cp .env.example .env
```

Add your keys:

TAVILY_API_KEY=your_api_key_here

## ðŸ“¦ Ollama Setup (Local LLMs)

This project uses Ollama to run local Large Language Models (LLMs) for planning, writing, and validation steps.

###ðŸ”¹ Models used in this project

- qwen3:8b â€” primary writer model

- deepseek-r1 â€” critic / planner model

- 1ï¸âƒ£ Install Ollama
- 2ï¸âƒ£ Start Ollama Server
- 3ï¸âƒ£ Pull Required Models
- 4ï¸âƒ£ Configure Model Names - The models are configured in .env file

## ðŸ“¦ Installation

```bash
pip install -r requirements.txt
```

## â–¶ï¸ Run the Application

```bash
streamlit run streamlit_app/app.py
```
## ðŸ—ï¸ Architecture

```mermaid
graph TD
    A[User Input] --> B[Plan Outline]
    B --> C{Brainstorm Section}
    C --> D[Research RAG + Web]
    D --> E[Write Section]
    E --> F{Validate}
    F -- Approved --> G[Save & Next]
    F -- Needs Revision --> E
    G --> H{All Sections Done?}
    H -- No --> C
    H -- Yes --> I[Synthesize Full Paper]
    I --> J[Download]
```

### Workflow Logic

1. **Plan** â€“ Generate a 5-section outline from the topic
2. **Brainstorm** â€“ Extract key points per section
3. **Research** â€“ Combine Tavily web search + RAG retrieval
4. **Write** â€“ Draft section content using gathered context
5. **Validate** â€“ Critic LLM reviews quality
6. **Revise Loop** â€“ Rewrites until approved or max retries
7. **Save & Next** â€“ Move to next section
8. **Synthesize** â€“ Merge all sections into a final paper

## ðŸ§  How It Works

- User provides seminar topic and context

- Relevant documents are retrieved via RAG

- LangGraph executes section-wise report generation

- Final structured seminar report is synthesized

- Output is displayed via Streamlit UI, can download .md file

## ðŸ“Œ Notes

- Designed with modularity and extensibility in mind

- Configuration handled via settings.py (environment-driven)

- Suitable for academic, research, and demo use cases
